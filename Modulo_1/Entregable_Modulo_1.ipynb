{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heNJLPGoadzh"
      },
      "source": [
        "# Entregable Modulo 1: Utilización, procesamiento y visualización de grandes volúmenes de datos "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuAk9Oe0adxq"
      },
      "source": [
        "## Jose Pablo Cobos Austria  A01274631 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_rl1BhradrK"
      },
      "source": [
        "### 1.- Descripcion de la actividad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLNhxwR5bx44"
      },
      "source": [
        "Este documento trata sobre el uso de la herramienta PySpark para el manejo de un conjunto de datos de gran volumen, para poder generar un modelo inteligente,y asimismo hacer uso de la aplicacion de Tableau para poder visualizar los datos "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rJgQgKgbzMt"
      },
      "source": [
        "### 2.- Configuracion del entorno de trabajo para usar PySpark "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dfU6EhnFaot"
      },
      "source": [
        "Lo primero que vamos hacer antes de iniciar con nuestra generación el modelo es la configuración del entorno que utilizaremos para trabajar con PySpark. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En cuánto a la información o características del sistema que podemos trabajar tenemos que estamos trabajando con el sistema operativo Arch Linux v6.0.9, un procesador Intel i5-10500H y un total de 16 gigas de RAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKSvLXn5GThz"
      },
      "source": [
        "A continuación importamos lo que son las todas las librerías Spark que utilizaremos para poder trabajar con los datos y generar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_boston"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Lo siguiente que se realizó fue iniciar una sesión de Spark qué será nuestro entorno de trabajo, bajo el nombre de Cobos Big Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2t3EnIzXFSB6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/11/25 13:07:02 WARN Utils: Your hostname, CubesLaptop resolves to a loopback address: 127.0.1.1; using 10.25.65.197 instead (on interface wlp0s20f3)\n",
            "22/11/25 13:07:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/11/25 13:07:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Cobos Big Data\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nos aseguramos que nuestra configuracion fuese la correcta y estuviera funcionando "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "RZpf31SPFZ9S",
        "outputId": "7a5c6825-4b4b-49dc-acf1-47788f7ba634"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://10.25.65.197:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Cobos Big Data</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fd513ebe3b0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk0Yyvt8cAvE"
      },
      "source": [
        "### 3.- Seleccion y carga de datos "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HkGxkurBcVP"
      },
      "source": [
        "Ya con nuestro entorno de trabajo ya configurado correctamente el siguiente paso a seguir fue la selección y carga de datos, utilizará fue encontrado del siguiente link: https://bit.ly/3iehRVO\n",
        "\n",
        "El peso total de dicho es más de  4 GB, por lo que cumple con el objetivo de analizar un dataset con un gran volumen de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CECfitKSGSMY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "df_main= spark.read.csv(\"/home/josecobos/Documentos/Escuela/IA_Parte2/Modulo_1/Trips_merged.csv\",inferSchema = True ,header=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64gQ3R8ZchXT"
      },
      "source": [
        "### 4.- Creacion del modelo inteligente usando MLib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3DPDOlYg5WT"
      },
      "source": [
        "##### 4.1 EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para la generacion del modelo inteligente lo primero que vamos a realizar es el EDA (Exploratory Data Analysis), para poder visualizar la informacion que tenemos de nuestros datos "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "j0xa4BElch8B",
        "outputId": "9e15f571-b175-4875-877c-d53e6135db10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- trip_id: string (nullable = true)\n",
            " |-- start_time: timestamp (nullable = true)\n",
            " |-- stop_time: timestamp (nullable = true)\n",
            " |-- bike_id: integer (nullable = true)\n",
            " |-- trip_duration: integer (nullable = true)\n",
            " |-- from_station_id: string (nullable = true)\n",
            " |-- from_station_name: string (nullable = true)\n",
            " |-- to_station_id: string (nullable = true)\n",
            " |-- to_station_name: string (nullable = true)\n",
            " |-- user_type: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- birth_year: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_main.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------------------+-------------------+-------+-------------+---------------+--------------------+-------------+--------------------+---------+------+----------+\n",
            "|trip_id|         start_time|          stop_time|bike_id|trip_duration|from_station_id|   from_station_name|to_station_id|     to_station_name|user_type|gender|birth_year|\n",
            "+-------+-------------------+-------------------+-------+-------------+---------------+--------------------+-------------+--------------------+---------+------+----------+\n",
            "|   4118|2013-06-27 12:11:00|2013-06-27 12:16:00|    480|          300|             85|Michigan Ave & Oa...|           28|Larrabee St & Men...|   Casual|  null|      null|\n",
            "|   4275|2013-06-27 14:44:00|2013-06-27 14:45:00|     77|           60|             32|Racine Ave & Cong...|           32|Racine Ave & Cong...|   Casual|  null|      null|\n",
            "|   4291|2013-06-27 14:58:00|2013-06-27 15:05:00|     77|          420|             32|Racine Ave & Cong...|           19|Loomis St & Taylo...|   Casual|  null|      null|\n",
            "|   4316|2013-06-27 15:06:00|2013-06-27 15:09:00|     77|          180|             19|Loomis St & Taylo...|           19|Loomis St & Taylo...|   Casual|  null|      null|\n",
            "|   4342|2013-06-27 15:13:00|2013-06-27 15:27:00|     77|          840|             19|Loomis St & Taylo...|           55|Halsted St & Jame...|   Casual|  null|      null|\n",
            "|   4480|2013-06-27 19:40:00|2013-06-27 22:28:00|     27|        10080|            340|Clark St & Wright...|           46|Wells St & Walton St|   Casual|  null|      null|\n",
            "|   4490|2013-06-27 18:45:00|2013-06-27 19:03:00|    418|         1080|             37|Dearborn St & Ada...|           76|Lake Shore Dr & M...|   Casual|  null|      null|\n",
            "|   4592|2013-06-27 19:34:00|2013-06-27 19:51:00|    170|         1020|             90|     Millennium Park|           75|Canal St & Jackso...|   Casual|  null|      null|\n",
            "|   4602|2013-06-27 19:45:00|2013-06-27 20:42:00|    353|         3420|             37|Dearborn St & Ada...|           37|Dearborn St & Ada...|   Casual|  null|      null|\n",
            "|   4607|2013-06-27 19:46:00|2013-06-27 19:57:00|    369|          660|             51|Clark St & Randol...|          340|Clark St & Wright...|   Casual|  null|      null|\n",
            "|   4617|2013-06-27 19:50:00|2013-06-27 20:19:00|    658|         1740|             44|State St & Randol...|           44|State St & Randol...|   Casual|  null|      null|\n",
            "|   4619|2013-06-27 19:52:00|2013-06-27 20:50:00|    533|         3480|             24|Fairbanks Ct & Gr...|           24|Fairbanks Ct & Gr...|   Casual|  null|      null|\n",
            "|   4644|2013-06-27 20:22:00|2013-06-27 20:50:00|    522|         1680|             20|Sheffield Ave & K...|           46|Wells St & Walton St|   Casual|  null|      null|\n",
            "|   4646|2013-06-27 20:22:00|2013-06-27 20:39:00|    477|         1020|             52|Michigan Ave & La...|           52|Michigan Ave & La...|   Casual|  null|      null|\n",
            "|   4647|2013-06-27 20:25:00|2013-06-27 20:39:00|    525|          840|             52|Michigan Ave & La...|           52|Michigan Ave & La...|   Casual|  null|      null|\n",
            "|   4666|2013-06-27 20:33:00|2013-06-27 21:22:00|    242|         2940|             44|State St & Randol...|           52|Michigan Ave & La...|   Casual|  null|      null|\n",
            "|   4793|2013-06-27 21:39:00|2013-06-27 21:51:00|    240|          720|             69|Damen Ave & Pierc...|           29|Noble St & Milwau...|   Casual|  null|      null|\n",
            "|   4863|2013-06-27 22:15:00|2013-06-27 22:36:00|    381|         1260|             61|Wood St & Milwauk...|           17|Wood St & Divisio...|   Casual|  null|      null|\n",
            "|   4865|2013-06-27 22:16:00|2013-06-27 22:42:00|    343|         1560|             85|Michigan Ave & Oa...|           85|Michigan Ave & Oa...|   Casual|  null|      null|\n",
            "|   4866|2013-06-27 22:17:00|2013-06-27 22:42:00|    220|         1500|             85|Michigan Ave & Oa...|           85|Michigan Ave & Oa...|   Casual|  null|      null|\n",
            "+-------+-------------------+-------------------+-------+-------------+---------------+--------------------+-------------+--------------------+---------+------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_main.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neMPhXTshBJe"
      },
      "source": [
        "##### 4.2 ETL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS0TA9MQhLyZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUpfshSmhMPx"
      },
      "source": [
        "##### 4.3  Generacion del modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOe72x6bciny"
      },
      "source": [
        "### 5.- Evaluacion del modelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR8UogKDci8J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etzwPyHTdlm3"
      },
      "source": [
        "### 6.- Visualizacion de los datos usando la herramienta de Tableu "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyfGxhQNdl3h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kp4YVRGdmOr"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "d2152fd7f0bbc62aa1baff8c990435d1e2c7175d001561303988032604c11a48"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
